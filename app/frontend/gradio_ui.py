"""Gradio UI for the Triton-backed inference service."""
from __future__ import annotations

import base64
import io
import os
from typing import Tuple

import gradio as gr
import httpx
from PIL import Image

BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8081")
BACKEND_TIMEOUT_SECONDS = float(os.getenv("BACKEND_TIMEOUT_SECONDS", "120"))
PREDICT_ENDPOINT = f"{BACKEND_URL.rstrip('/')}/predict"
DEFAULT_IMAGE_PATH = os.path.join(os.path.dirname(__file__), "../backend/8.png")
SERVER_NAME = os.getenv("GRADIO_SERVER_NAME", "0.0.0.0")
SERVER_PORT = int(os.getenv("GRADIO_SERVER_PORT", os.getenv("PORT", "7860")))
SHARE_INTERFACE = os.getenv("GRADIO_SHARE", "false").lower() in {"1", "true", "yes", "y"}


def _decode_image(image_b64: str) -> Image.Image:
    return Image.open(io.BytesIO(base64.b64decode(image_b64)))


def _call_backend(image: Image.Image) -> Tuple[Image.Image, Image.Image, str]:
    if image is None:
        raise gr.Error("Please upload an image before submitting.")

    buffer = io.BytesIO()
    image.save(buffer, format="PNG")
    buffer.seek(0)

    with httpx.Client(timeout=BACKEND_TIMEOUT_SECONDS) as client:
        files = {"file": ("upload.png", buffer.getvalue(), "image/png")}
        try:
            response = client.post(PREDICT_ENDPOINT, files=files)
            response.raise_for_status()
        except httpx.HTTPError as exc:  # pragma: no cover - network failure
            raise gr.Error(f"Backend request failed: {exc}") from exc
        payload = response.json()

    overlay = _decode_image(payload["overlay"])
    mask = _decode_image(payload["mask"])
    coverage_pct = round(payload["coverage"] * 100, 2)
    status = f"Latency: {payload['latency_seconds']:.3f}s Â· Coverage: {coverage_pct}%"
    return overlay, mask, status


def build_interface() -> gr.Blocks:
    default_image = None
    if os.path.exists(DEFAULT_IMAGE_PATH):
        default_image = Image.open(DEFAULT_IMAGE_PATH)

    with gr.Blocks(title="Polyp Segmentation", theme=gr.themes.Soft()) as demo:
        gr.Markdown(
            """
            # ðŸ§¬ Polyp Segmentation
            Upload an image to see the segmentation mask generated by the Triton-backed service.
            The service returns the mask, overlay and latency so you can evaluate performance quickly.
            """
        )

        with gr.Row():
            with gr.Column(scale=1):
                input_image = gr.Image(type="pil", label="Input Image", value=default_image)
                submit = gr.Button("Run Inference", variant="primary")
            with gr.Column(scale=1):
                overlay_output = gr.Image(type="pil", label="Overlay", interactive=False)
                mask_output = gr.Image(type="pil", label="Mask", interactive=False)
                status = gr.Textbox(label="Inference Summary", interactive=False)

        submit.click(
            fn=_call_backend,
            inputs=input_image,
            outputs=[overlay_output, mask_output, status],
        )

    return demo


if __name__ == "__main__":
    interface = build_interface()
    interface.launch(server_name="0.0.0.0", server_port=7860)
