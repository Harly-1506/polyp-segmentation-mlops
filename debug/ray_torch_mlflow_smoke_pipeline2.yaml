# PIPELINE DEFINITION
# Name: ray-torch-mlflow-smoke-pipeline
# Inputs:
#    experiment_name: str [Default: 'kubeflow-ray-smoke']
#    mlflow_tracking_uri: str [Default: 'http://mlflow-tracking.mlflow.svc.cluster.local:5000']
#    ray_address: str [Default: 'ray://kuberay-raycluster-head-svc.development.svc.cluster.local:10001']
#    ray_namespace: str [Default: 'default']
components:
  comp-ray-torch-mlflow-smoke-test:
    executorLabel: exec-ray-torch-mlflow-smoke-test
    inputDefinitions:
      parameters:
        experiment_name:
          defaultValue: kubeflow-ray-smoke
          isOptional: true
          parameterType: STRING
        mlflow_tracking_uri:
          parameterType: STRING
        ray_address:
          parameterType: STRING
        ray_namespace:
          defaultValue: default
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-ray-torch-mlflow-smoke-test:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - ray_torch_mlflow_smoke_test
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'mlflow==3.1.0'\
          \  &&  python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.2'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef ray_torch_mlflow_smoke_test(\n    ray_address: str,\n    mlflow_tracking_uri:\
          \ str,\n    experiment_name: str = \"kubeflow-ray-smoke\",\n    ray_namespace:\
          \ str = \"default\",\n) -> str:\n    import os, sys, platform, json, socket,\
          \ tempfile, subprocess\n    from urllib.parse import urlparse\n\n    def\
          \ p(msg): print(msg)\n\n    # --- DRIVER ENV ---\n    p(\"=== DRIVER ENV\
          \ INFO (before Ray connect) ===\")\n    p(\"python: {}\".format(sys.executable))\n\
          \    p(\"python_version: {}\".format(sys.version))\n    p(\"platform: {}\"\
          .format(platform.platform()))\n    p(\"ray_address(param): {}\".format(ray_address))\n\
          \    p(\"mlflow_tracking_uri(param): {}\".format(mlflow_tracking_uri))\n\
          \    p(\"ray_namespace(param): {}\".format(ray_namespace))\n    p(\"env.RAY_ADDRESS:\
          \ {}\".format(os.environ.get(\"RAY_ADDRESS\")))\n    p(\"env.MLFLOW_TRACKING_URI:\
          \ {}\".format(os.environ.get(\"MLFLOW_TRACKING_URI\")))\n    try:\n    \
          \    pip_freeze = subprocess.check_output([sys.executable, \"-m\", \"pip\"\
          , \"freeze\"]).decode()\n    except Exception as e:\n        pip_freeze\
          \ = \"<pip freeze failed: {}>\".format(e)\n    for line in pip_freeze.splitlines()[:50]:\
          \ p(\"  \" + line)\n\n    # best-effort: kh\xF4ng y\xEAu c\u1EA7u torch\
          \ tr\xEAn driver\n    try:\n        import torch as _torch\n        driver_has_torch,\
          \ driver_torch_detail = True, _torch.__version__\n    except Exception as\
          \ e:\n        driver_has_torch, driver_torch_detail = False, \"import torch\
          \ failed on driver: {}\".format(e)\n    p(\"driver_has_torch={}; detail={}\"\
          .format(driver_has_torch, driver_torch_detail))\n\n    import ray\n\n  \
          \  # --- sanitize ---\n    ray_address = (ray_address or \"\").strip()\n\
          \    mlflow_tracking_uri = (mlflow_tracking_uri or \"\").strip()\n    ray_namespace\
          \ = (ray_namespace or \"\").strip()\n\n    # --- preflight TCP ---\n   \
          \ u = urlparse(ray_address)\n    host, port = (u.hostname or ray_address),\
          \ (u.port or 10001)\n    p(\"=== Preflight: TCP connect to {}:{} ===\".format(host,\
          \ port))\n    try:\n        s = socket.create_connection((host, port), timeout=5);\
          \ s.close()\n        p(\"Preflight OK: TCP reachable.\")\n    except Exception\
          \ as e:\n        p(\"[FATAL] Cannot reach Ray client at {}:{}\\nError: {}\"\
          .format(host, port, e))\n        sys.exit(1)\n\n    # --- connect ---\n\
          \    p(\"=== Connecting to Ray Cluster ===\")\n    try:\n        ray.init(address=ray_address,\
          \ namespace=ray_namespace, ignore_reinit_error=True, log_to_driver=True)\n\
          \        p(\"Connected to Ray.\")\n        p(\"Ray version: {}\".format(ray.__version__))\n\
          \        p(\"Ray cluster resources: {}\".format(ray.cluster_resources()))\n\
          \    except Exception as e:\n        import traceback as _tb\n        p(\"\
          [FATAL] ray.init failed: {}\".format(repr(e))); _tb.print_exc(); sys.exit(1)\n\
          \n    # --- env probe on worker: \u0111\u1EA3m b\u1EA3o env th\u1EADt s\u1EF1\
          \ d\xF9ng c\xF9ng base (conda) ---\n    @ray.remote\n    def env_probe():\n\
          \        import sys, platform\n        try:\n            import numpy as\
          \ np\n            npv = \"{} @ {}\".format(np.__version__, getattr(np, \"\
          __file__\", \"\"))\n        except Exception as e:\n            npv = \"\
          IMPORT ERROR: {}\".format(e)\n        try:\n            import torch\n \
          \           tv = torch.__version__\n        except Exception as e:\n   \
          \         tv = \"IMPORT ERROR: {}\".format(e)\n        return {\n      \
          \      \"python\": sys.version,\n            \"executable\": sys.executable,\n\
          \            \"platform\": platform.platform(),\n            \"numpy\":\
          \ npv,\n            \"torch\": tv,\n            \"sys_path0\": sys.path[0]\
          \ if sys.path else \"\",\n        }\n\n    p(\"=== Probing worker environment\
          \ ===\")\n    w_env = ray.get(env_probe.remote())\n    p(json.dumps(w_env,\
          \ indent=2))\n\n    # --- torch small op on worker ---\n    @ray.remote\n\
          \    def torch_probe():\n        info = {}\n        try:\n            import\
          \ torch\n            info[\"torch_ok\"] = True\n            info[\"torch_version\"\
          ] = torch.__version__\n            cuda = torch.cuda.is_available()\n  \
          \          info[\"cuda_available\"] = cuda\n            info[\"cuda_device_count\"\
          ] = torch.cuda.device_count() if cuda else 0\n            x = torch.randn(8,\
          \ 4) @ torch.randn(4, 3)\n            info[\"mean\"] = float(x.mean().item())\n\
          \        except Exception as e:\n            info[\"torch_ok\"] = False\n\
          \            info[\"error\"] = str(e)\n        return info\n\n    p(\"===\
          \ Probing torch on worker ===\")\n    t_probe = ray.get(torch_probe.remote())\n\
          \    p(json.dumps(t_probe, indent=2))\n\n    # --- (optional) tiny trainer\
          \ ---\n    trainer_result, trainer_error = None, None\n    try:\n      \
          \  from ray.train import ScalingConfig\n        from ray.train.torch import\
          \ TorchTrainer\n\n        def train_loop_per_worker():\n            import\
          \ torch\n            m = torch.nn.Linear(10, 2)\n            opt = torch.optim.SGD(m.parameters(),\
          \ lr=0.01)\n            loss_fn = torch.nn.CrossEntropyLoss()\n        \
          \    x = torch.randn(16, 10); y = torch.randint(0, 2, (16,))\n         \
          \   for _ in range(2):\n                opt.zero_grad(); out = m(x); loss\
          \ = loss_fn(out, y); loss.backward(); opt.step()\n            return {\"\
          final_loss\": float(loss.detach().cpu().item())}\n\n        use_gpu = bool(t_probe.get(\"\
          cuda_available\"))\n        trainer = TorchTrainer(train_loop_per_worker,\
          \ scaling_config=ScalingConfig(num_workers=1, use_gpu=use_gpu))\n      \
          \  trainer_result = trainer.fit()\n        p(\"TorchTrainer result: {}\"\
          .format(trainer_result))\n    except Exception as e:\n        trainer_error\
          \ = str(e)\n        p(\"TorchTrainer failed: {}\".format(trainer_error))\n\
          \n    # --- MLflow ---\n    import mlflow\n    p(\"=== Logging to MLflow\
          \ ===\")\n    mlflow.set_tracking_uri(mlflow_tracking_uri)\n    mlflow.set_experiment(experiment_name)\n\
          \    with mlflow.start_run(run_name=\"ray-torch-mlflow-smoke\") as run:\n\
          \        mlflow.log_param(\"ray_address\", ray_address)\n        mlflow.log_param(\"\
          ray_namespace\", ray_namespace)\n        mlflow.log_param(\"driver_has_torch\"\
          , driver_has_torch)\n        mlflow.log_param(\"driver_torch_detail\", driver_torch_detail)\n\
          \        for k in [\"python\", \"executable\", \"platform\", \"numpy\",\
          \ \"torch\"]:\n            mlflow.log_param(\"worker_\"+k, str(w_env.get(k)))\n\
          \        for k in [\"torch_ok\", \"torch_version\", \"cuda_available\",\
          \ \"cuda_device_count\", \"mean\"]:\n            if k in t_probe: mlflow.log_param(\"\
          worker_\"+k, str(t_probe[k]))\n        if trainer_result and getattr(trainer_result,\
          \ \"metrics\", None):\n            try: mlflow.log_metric(\"trainer_final_loss\"\
          , float(trainer_result.metrics.get(\"final_loss\", -1)))\n            except\
          \ Exception: pass\n        # artifact debug\n        payload = {\n     \
          \       \"driver\": {\n                \"python\": sys.version, \"executable\"\
          : sys.executable,\n                \"platform\": platform.platform(),\n\
          \                \"driver_has_torch\": driver_has_torch,\n             \
          \   \"driver_torch_detail\": driver_torch_detail,\n                \"pip_freeze\"\
          : pip_freeze,\n            },\n            \"ray\": {\"version\": ray.__version__,\
          \ \"cluster_resources\": ray.cluster_resources()},\n            \"worker_env\"\
          : w_env, \"torch_probe\": t_probe, \"trainer_error\": trainer_error,\n \
          \       }\n        fd, tmp = tempfile.mkstemp(prefix=\"ray_torch_mlflow_debug_\"\
          , suffix=\".json\")\n        with os.fdopen(fd, \"w\") as f: json.dump(payload,\
          \ f, indent=2)\n        mlflow.log_artifact(tmp, artifact_path=\"debug\"\
          )\n        p(\"MLflow run id: {}\".format(run.info.run_id))\n    return\
          \ json.dumps({\"worker_torch_ok\": t_probe.get(\"torch_ok\", False)})\n\n"
        image: rayproject/ray:2.48.0-py312-cpu
pipelineInfo:
  name: ray-torch-mlflow-smoke-pipeline
root:
  dag:
    tasks:
      ray-torch-mlflow-smoke-test:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-ray-torch-mlflow-smoke-test
        inputs:
          parameters:
            experiment_name:
              componentInputParameter: experiment_name
            mlflow_tracking_uri:
              componentInputParameter: mlflow_tracking_uri
            ray_address:
              componentInputParameter: ray_address
            ray_namespace:
              componentInputParameter: ray_namespace
        taskInfo:
          name: ray-torch-mlflow-smoke-test
  inputDefinitions:
    parameters:
      experiment_name:
        defaultValue: kubeflow-ray-smoke
        isOptional: true
        parameterType: STRING
      mlflow_tracking_uri:
        defaultValue: http://mlflow-tracking.mlflow.svc.cluster.local:5000
        isOptional: true
        parameterType: STRING
      ray_address:
        defaultValue: ray://kuberay-raycluster-head-svc.development.svc.cluster.local:10001
        isOptional: true
        parameterType: STRING
      ray_namespace:
        defaultValue: default
        isOptional: true
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.14.2
